{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e9c724-dd3c-4674-a0e8-dc684df0587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "#import spikeinterface.full as si\n",
    "#from spikeinterface.sortingcomponents.motion import correct_motion_on_peaks, interpolate_motion\n",
    "#from spikeinterface.sorters import run_sorter\n",
    "\n",
    "from si_utils import *\n",
    "from SI_H2P import si_h2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52eb1a93-0d09-4c59-9172-467eaa38be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Setting up folders and reading raw recording...\n",
      "Step 2: Preprocessing raw recording...\n",
      "/ix1/pmayo/lab_NHPdata/kendra_scrappy_0125a_g0/figs/preprocess/noise_dists.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8546f3c2e5d34ae5be242d3a819a4072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 20 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bf61b0e8bc4801b2d77c462cc76a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 20 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384,)\n",
      "bad_channel_ids ['imec0.ap#AP191']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9898d298a85f49cbbba4bce17d562037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 20 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbeb70e88e44c138e4f2b8f41b832c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect peaks using locally_exclusive (workers: 40 processes):   0%|          | 0/3379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a047a331e4b54121aa0a847c37e1382d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "localize peaks using center_of_mass (workers: 40 processes):   0%|          | 0/3379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Estimating and applying motion correction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758a6ba3c6be42c6bd8fc8e128383222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 20 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5f7aa7188e4a01b5f479814b828008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect and localize (workers: 40 processes):   0%|          | 0/3379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd0c976b4a44f05965b7c55c7d66e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cross correlation:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa008ae3e3074a61bc3e57a89e19c436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solve:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Saving drift-corrected recording to disk...\n",
      "write_binary_recording \n",
      "engine=process - n_jobs=40 - samples_per_chunk=29,999 - chunk_memory=87.89 MiB - total_memory=3.43 GiB - chunk_duration=1.00s (999.97 ms)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed46871199184373a5d65aa6991db3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "write_binary_recording (workers: 40 processes):   0%|          | 0/3379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cc0d033d8b48b3a391233d3d9cafd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect peaks using locally_exclusive (workers: 40 processes):   0%|          | 0/3379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d21a3cf5774df1adb4a9da9d0fb1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "localize peaks using center_of_mass (workers: 40 processes):   0%|          | 0/3379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/rec_output.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m IN2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m spikeglx_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ix1/pmayo/lab_NHPdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIN1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msi_h2p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspikeglx_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMEC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIN2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrift_preset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdredge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_figs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Packages/spikeinterface/SI_H2P.py:69\u001b[0m, in \u001b[0;36msi_h2p\u001b[0;34m(spikeglx_folder, IMEC, drift_preset, plot_figs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         plot_peaks_from_recording(RECORDING, save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(figs_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeak_times_depths2.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     68\u001b[0m     write_recording_details_txt(RAW_RECORDING, preprocess_folder \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_rec_output.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     \u001b[43mwrite_recording_details_txt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRECORDING\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpreprocess_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/rec_output.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m############################################# RUN KILOSORT ##############################################\u001b[39;00m\n\u001b[1;32m     72\u001b[0m params \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mget_default_sorter_params(sorter_name_or_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkilosort4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Packages/spikeinterface/si_utils/write_recording_details_txt.py:13\u001b[0m, in \u001b[0;36mwrite_recording_details_txt\u001b[0;34m(rec, save_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m dtype \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_dtype()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# opening a .txt file to output the values of raw_rec\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Step 4: Write the metadata to the file\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of channels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_channels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSampling frequency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msampling_frequency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/rec_output.txt'"
     ]
    }
   ],
   "source": [
    "IN1 = 'kendra_scrappy_0125a_g0'\n",
    "IN2 = 0\n",
    "\n",
    "spikeglx_folder = f\"/ix1/pmayo/lab_NHPdata/{IN1}/\"\n",
    "\n",
    "si_h2p(spikeglx_folder, IMEC=IN2, drift_preset=\"dredge\", plot_figs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b9ccc-81e8-4be4-bf21-24fbd3174949",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN1 = 'kendra_scrappy_0124a_g0'\n",
    "IN2 = 0\n",
    "\n",
    "save_path = f\"/ix1/pmayo/lab_NHPdata/{IN1}/{IN1}_imec{IN2}/dredge/corrected/traces_cached_seg0.raw\"\n",
    "#probe_path = f\"/ix1/pmayo/lab_NHPdata/{IN1}/{IN1}_imec{IN2}/{IN1}_t0.imec{IN2}.ap_kilosortChanMap.mat\"\n",
    "probe_path = f\"/ix1/pmayo/lab_NHPdata/{IN1}/{IN1}_imec{IN2}/dredge/corrected/probe.prb\"\n",
    "\n",
    "print(save_path)\n",
    "print(probe_path)\n",
    "\n",
    "kilosort_h2p(save_path,probe_path,run_ks=True,temp_wh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1f525-7cbe-4940-9341-4aac5929a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import spikeinterface.full as si  # import core only\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "from spikeinterface.sortingcomponents.motion import correct_motion_on_peaks\n",
    "\n",
    "from kilosort import io\n",
    "\n",
    "#import spikeinterface.extractors as se\n",
    "#import spikeinterface.preprocessing as spre\n",
    "#import spikeinterface.sorters as ss\n",
    "#import spikeinterface.postprocessing as spost\n",
    "#import spikeinterface.qualitymetrics as sqm\n",
    "#import spikeinterface.comparison as sc\n",
    "#import spikeinterface.exporters as sexp\n",
    "#import spikeinterface.curation as scur\n",
    "#import spikeinterface.widgets as sw\n",
    "\n",
    "#from spikeinterface.preprocessing import get_motion_parameters_preset, get_motion_presets\n",
    "from spikeinterface.sortingcomponents.motion import estimate_motion, interpolate_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39c0aa-75ab-45d9-a401-b6c5df2488a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### INPUTS ###############\n",
    "IN1 = 'kendra_scrappy_0124a_g0'\n",
    "IN2 = 0\n",
    "\n",
    "spikeglx_folder = f\"/ix1/pmayo/lab_NHPdata/{IN1}/\"\n",
    "preprocess_folder = spikeglx_folder+\"figs/preprocess\"\n",
    "motion_folder = spikeglx_folder+f\"/{IN1}_imec{IN2}/motion\"\n",
    "\n",
    "os.makedirs(preprocess_folder, exist_ok=True)\n",
    "\n",
    "#spikeglx_folder = '/ix1/pmayo/lab_NHPdata/kendra_scrappy_0130a_g0'\n",
    "#dredge_type = 'lfp' # ap\n",
    "\n",
    "stream_names, stream_ids = si.get_neo_streams('spikeglx', spikeglx_folder)\n",
    "stream_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970796b8-03be-4f77-8198-556b6f09f46f",
   "metadata": {},
   "source": [
    "# Read in data\n",
    "\n",
    "* Neuropixels -- [read_spikeglx](https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.extractors.read_spikeglx)\n",
    "* Plexon (after converting to binary) -- [read_binary](https://spikeinterface.readthedocs.io/en/stable/api.html#spikeinterface.core.read_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddf10f-c642-4a63-b111-deaee5488afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw recording \n",
    "RAW_REC = si.read_spikeglx(spikeglx_folder, stream_name=f'imec{IN2}.ap', load_sync_channel=False)\n",
    "RAW_REC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563a9ba-3c07-42ae-a7ed-ac207754934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can estimate the noise on the scaled traces (microV) or on the raw one (which is in our case int16).\n",
    "noise_levels_microV = si.get_noise_levels(RAW_REC, return_scaled=True)\n",
    "noise_levels_int16 = si.get_noise_levels(RAW_REC, return_scaled=False)\n",
    "\n",
    "print(noise_levels_int16.shape)\n",
    "\n",
    "# Create subplots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot scaled traces (microV)\n",
    "axes[0].hist(noise_levels_microV, bins=np.arange(5, 30, 2.5))\n",
    "axes[0].set_title('scaled traces (microV)')\n",
    "axes[0].set_xlabel('noise [microV]')\n",
    "\n",
    "# Plot raw traces (int16)\n",
    "axes[1].hist(noise_levels_int16, bins=np.arange(5, 30, 2.5))\n",
    "axes[1].set_title('raw traces (int16)')\n",
    "axes[1].set_xlabel('noise [int16 units]')\n",
    "\n",
    "output_path = os.path.join(preprocess_folder, 'noise_dists.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e26fa4d-295d-4e62-87bd-4edc2e57f04a",
   "metadata": {},
   "source": [
    "# Preprocessing recording\n",
    "1. Highpass filter\n",
    "2. Tossing bad channels\n",
    "3. Common reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a32a1-e2ed-4541-8222-27a78c183dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_recording(raw_rec, save_path=None):\n",
    "    raw_rec = raw_rec.astype('float32')\n",
    "    \n",
    "    rec1 = si.highpass_filter(raw_rec, freq_min=400.)\n",
    "    bad_channel_ids, channel_labels = si.detect_bad_channels(rec1)\n",
    "    rec2 = rec1.remove_channels(bad_channel_ids)\n",
    "    print('bad_channel_ids', bad_channel_ids)\n",
    "    \n",
    "    rec3 = si.phase_shift(rec2)\n",
    "    rec4 = si.common_reference(rec3, operator=\"median\", reference=\"global\")\n",
    "    rec = rec4\n",
    "\n",
    "    if save_path is not None:\n",
    "        # here we use static plot using matplotlib backend\n",
    "        fig, axs = plt.subplots(ncols=3, figsize=(20, 10))\n",
    "        \n",
    "        si.plot_traces(rec1, backend='matplotlib',  clim=(-50, 50), ax=axs[0])\n",
    "        si.plot_traces(rec3, backend='matplotlib',  clim=(-50, 50), ax=axs[1])\n",
    "        si.plot_traces(rec4, backend='matplotlib',  clim=(-50, 50), ax=axs[2])\n",
    "        for i, label in enumerate(('hp filter', 'phase shift', 'cmr')):\n",
    "            axs[i].set_title(label)\n",
    "    \n",
    "        \n",
    "            output_path = os.path.join(save_path, 'preprocess_steps.png')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_path)\n",
    "    \n",
    "        # plot some channels\n",
    "        fig, ax = plt.subplots(figsize=(20, 10))\n",
    "        some_chans = rec.channel_ids[[100, 150, 200, ]]\n",
    "        si.plot_traces({'filter':rec1, 'cmr': rec4}, backend='matplotlib', mode='line', ax=ax, channel_ids=some_chans)\n",
    "\n",
    "        output_path = os.path.join(save_path, 'preprocess_chans.png')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_path)\n",
    "    \n",
    "    return rec, bad_channel_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646c169-703c-4bbd-a1c4-3494d955df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "REC, bad_channel_ids = preprocess_recording(RAW_REC, save_path=None) #preprocess_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b4dc2-5e8b-4ef9-88aa-42696fc6f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probeinterface import ProbeGroup, write_prb\n",
    "\n",
    "probe_path = DATA_DIRECTORY / 'probe.prb'\n",
    "\n",
    "probe = REC.get_probe()  # From SpikeInterface tutorial, or recording.get_probe()\n",
    "pg = ProbeGroup()\n",
    "pg.add_probe(probe)\n",
    "\n",
    "# CHANGE THIS PATH to wherever you want to save your probe file.\n",
    "write_prb(probe_path, pg)\n",
    "\n",
    "print(probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c3fc3-456a-4d72-a088-24ce45fd749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_levels_int16 = si.get_noise_levels(REC, return_scaled=False)\n",
    "\n",
    "job_kwargs = dict(n_jobs=40, chunk_duration='1s', progress_bar=True)\n",
    "peaks = detect_peaks(REC,  method='locally_exclusive', noise_levels=noise_levels_int16,\n",
    "                     detect_threshold=5, radius_um=50., **job_kwargs)\n",
    "\n",
    "peak_locations = localize_peaks(REC, peaks, method='center_of_mass', radius_um=50., **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702c3fb-ad49-4ca1-af8f-297923e27e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for drifts\n",
    "fs = REC.sampling_frequency\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.scatter(peaks['sample_index'] / fs, peak_locations['y'], color='k', marker='.',  alpha=0.002)\n",
    "\n",
    "output_path = os.path.join(preprocess_folder, 'peak_times_depths1.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d66ef5-1a1d-4304-bc33-39064a41fd8a",
   "metadata": {},
   "source": [
    "# Motion/Drift Detection\n",
    "1. Bandpass filter\n",
    "2. Common reference\n",
    "3. Correct motion w/ dredge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319bf77-95bd-447a-bb94-3e1ce60f39eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_drift_correction(raw_rec, bad_channel_ids):\n",
    "    rec1 = raw_rec.astype('float32')\n",
    "    \n",
    "    rec2 = si.bandpass_filter(rec1, freq_min=300.0, freq_max=5000.0)\n",
    "    rec3 = si.common_reference(rec2, reference=\"global\", operator=\"median\")\n",
    "\n",
    "    rec4 = rec3.remove_channels(bad_channel_ids)\n",
    "    print('bad_channel_ids', bad_channel_ids)\n",
    "    \n",
    "    return rec4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd513641-159f-4a68-be2e-b7527c4d5bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILT_REC1 = preprocess_for_drift_correction(RAW_REC, bad_channel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96b7c9-2fb6-408a-ad6c-49a94628056f",
   "metadata": {},
   "source": [
    "## High-level API --> for actually doing drift correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b70f6-aa42-4f01-9619-91cbd06d291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIFT_REC = si.correct_motion(recording=FILT_REC1, preset=\"dredge\", folder=motion_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4e8f6-ffe9-4dcb-be9d-b8d9f19cadd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_info = si.load_motion_info(motion_folder)\n",
    "motion = motion_info[\"motion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555e0d8-dbdb-40e2-8607-4da3b4e3848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "si.plot_motion_info(motion_info, FILT_REC1, figure=fig, depth_lim=(400, 1000), color_amplitude=True, amplitude_cmap=\"inferno\", scatter_decimate=10,)\n",
    "\n",
    "output_path = os.path.join(preprocess_folder, 'motion_info.png')\n",
    "plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7aee3f-6fbd-4b31-add7-7fb65ca54c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 8), sharey=True)\n",
    "\n",
    "ax = axs[0]\n",
    "si.plot_probe_map(FILT_REC1, ax=ax)\n",
    "\n",
    "peaks = motion_info[\"peaks\"]\n",
    "sr = FILT_REC1.get_sampling_frequency()\n",
    "time_lim0 = 750.0\n",
    "time_lim1 = 1500.0\n",
    "mask = (peaks[\"sample_index\"] > int(sr * time_lim0)) & (peaks[\"sample_index\"] < int(sr * time_lim1))\n",
    "sl = slice(None, None, 5)\n",
    "amps = np.abs(peaks[\"amplitude\"][mask][sl])\n",
    "amps /= np.quantile(amps, 0.95)\n",
    "c = plt.get_cmap(\"inferno\")(amps)\n",
    "axs[0].set_title('Estimated peak locations (pre-dredge)')\n",
    "\n",
    "color_kargs = dict(alpha=0.2, s=2, c=c)\n",
    "\n",
    "peak_locations = motion_info[\"peak_locations\"]\n",
    "# color='black',\n",
    "ax.scatter(peak_locations[\"x\"][mask][sl], peak_locations[\"y\"][mask][sl], **color_kargs)\n",
    "\n",
    "peak_locations2 = correct_motion_on_peaks(peaks, peak_locations, motion, FILT_REC1)\n",
    "\n",
    "ax = axs[1]\n",
    "si.plot_probe_map(FILT_REC1, ax=ax)\n",
    "#  color='black',\n",
    "ax.scatter(peak_locations2[\"x\"][mask][sl], peak_locations2[\"y\"][mask][sl], **color_kargs)\n",
    "axs[1].set_title('Corrected peak locations (post-dredge)')\n",
    "\n",
    "ax.set_ylim(400, 600)\n",
    "\n",
    "output_path = os.path.join(preprocess_folder, 'spatial_spread.png')\n",
    "plt.savefig(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea5f4b-a42b-4cbf-93d7-c3d41dd593ad",
   "metadata": {},
   "source": [
    "# Apply Drift Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83bf35c-b552-40ad-8446-61b8da729ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from spikeinterface.sortingcomponents.motion import interpolate_motion\n",
    "\n",
    "motion_info = si.load_motion_info(motion_folder)\n",
    "motion = motion_info[\"motion\"]\n",
    "\n",
    "REC_CORRECTED = interpolate_motion(recording=REC, motion=motion_info['motion'], **motion_info['parameters']['interpolate_motion_kwargs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c1f620-3275-4be3-961b-9fb77d791f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_kwargs = dict(n_jobs=40, chunk_duration='1s', progress_bar=True)\n",
    "\n",
    "DATA_DIRECTORY = Path(spikeglx_folder+f\"/{IN1}_imec{IN2}/corrected\")\n",
    "\n",
    "REC_CORRECTED = REC_CORRECTED.save(folder=DATA_DIRECTORY, format='binary', **job_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2336ebd-1d9a-478b-9604-2ca3a3d1d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from kilosort import io\n",
    "\n",
    "#DATA_DIRECTORY = Path(spikeglx_folder+f\"/{IN1}_imec{IN2}/corrected\")\n",
    "#DATA_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#dtype = np.int16\n",
    "#filename, N, c, s, fs, probe_path = io.spikeinterface_to_binary(\n",
    "#    REC_CORRECTED, DATA_DIRECTORY, data_name='kendra_scrappy_0130a_g0_t0.imec0_DREDGE.ap.bin', dtype=dtype,\n",
    "#    chunksize=60000, export_probe=True, probe_name='probe.prb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe6b2e-998c-4d6c-99b8-51f2b3b54874",
   "metadata": {},
   "source": [
    "# Test run Kilosort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd829bf-8f85-4fd8-a7eb-fa0ab68c1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kilosort import run_kilosort, DEFAULT_SETTINGS\n",
    "\n",
    "# NOTE: 'n_chan_bin' is a required setting, and should reflect the total number\n",
    "#       of channels in the binary file, while probe['n_chans'] should reflect\n",
    "#       the number of channels that contain ephys data. In many cases these will\n",
    "#       be the same, but not always. For example, neuropixels data often contains\n",
    "#       385 channels, where 384 channels are for ephys traces and 1 channel is\n",
    "#       for some other variable. In that case, you would specify\n",
    "#       'n_chan_bin': 385.\n",
    "\n",
    "# Specify probe configuration.\n",
    "probe = io.load_probe(probe_path)\n",
    "print(probe)\n",
    "\n",
    "settings = DEFAULT_SETTINGS\n",
    "settings['probe'] = probe\n",
    "settings['n_chan_bin'] = probe['n_chan']+2\n",
    "settings['fs'] = 30000\n",
    "settings['data_dir'] = DATA_DIRECTORY.parent\n",
    "#print(settings)\n",
    "\n",
    "# This command will both run the spike-sorting analysis and save the results to\n",
    "# `DATA_DIRECTORY`.\n",
    "ops, st, clu, tF, Wall, similar_templates, is_ref, \\\n",
    "    est_contam_rate, kept_spikes = run_kilosort(\n",
    "        settings=settings, probe=probe, data_dtype='int16', save_preprocessed_copy=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c63c1-3905-458e-a77f-9e9e46fc2bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce785971-464a-40d3-90d0-e431fcdfd7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
