{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1d79ca-bcf1-4981-987f-7a80411664d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import medicine\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from si_utils import *\n",
    "\n",
    "from spikeinterface.core import set_global_job_kwargs, get_global_job_kwargs\n",
    "from spikeinterface.core.motion import Motion\n",
    "from spikeinterface.sortingcomponents.motion.motion_interpolation import InterpolateMotionRecording\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks\n",
    "from spikeinterface.sortingcomponents.peak_localization import localize_peaks\n",
    "from spikeinterface.extractors import read_spikeglx, get_neo_streams\n",
    "\n",
    "def si_preprocess_with_medicine(spikeglx_folder, IMEC=0):\n",
    "\n",
    "    t = time.time()\n",
    "    global_job_kwargs = dict(n_jobs=40, chunk_duration='1s', progress_bar=True)\n",
    "    print(get_global_job_kwargs())\n",
    "    set_global_job_kwargs(**global_job_kwargs)\n",
    "    \n",
    "    print(\"Step 1: Setting up folders and reading raw recording...\")\n",
    "    medicine_output_dir, preprocess_folder, figs_folder = make_folder_paths(spikeglx_folder, IMEC)\n",
    "    print(preprocess_folder)\n",
    "    \n",
    "    # SpikeInterface recording object you would like to do motion correction for\n",
    "    stream_names, stream_ids = get_neo_streams('spikeglx', spikeglx_folder)\n",
    "    recording = read_spikeglx(spikeglx_folder, stream_name=f'imec{IMEC}.ap', load_sync_channel=False)\n",
    "\n",
    "    if not os.path.isdir(medicine_output_dir):     \n",
    "        print(\"Step 2: Estimating motion correction...\")\n",
    "        \n",
    "        # Detect, extract, and localize peaks, such as with the following pipeline\n",
    "        peaks = detect_peaks(recording, method=\"locally_exclusive\")\n",
    "        peak_locations = localize_peaks(recording, peaks, method=\"monopolar_triangulation\")\n",
    "        \n",
    "        # Create directory to store MEDiCINe outputs for this recording\n",
    "        #medicine_output_dir = Path('path/to/medicine/output/directory')\n",
    "        medicine_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Run MEDiCINe to estimate motion\n",
    "        medicine.run_medicine(\n",
    "            peak_amplitudes=peaks['amplitude'],\n",
    "            peak_depths=peak_locations['y'],\n",
    "            peak_times=peaks['sample_index'] / recording.get_sampling_frequency(),\n",
    "            output_dir=medicine_output_dir,\n",
    "        )\n",
    "    \n",
    "    # Load motion estimated by MEDiCINe\n",
    "    motion = np.load(medicine_output_dir / 'motion.npy')\n",
    "    time_bins = np.load(medicine_output_dir / 'time_bins.npy')\n",
    "    depth_bins = np.load(medicine_output_dir / 'depth_bins.npy')\n",
    "\n",
    "    print(\"Step 3: Applying motion correction...\")\n",
    "    # Use interpolation to correct for motion estimated by MEDiCINe\n",
    "    motion_object = Motion(\n",
    "        displacement=motion,\n",
    "        temporal_bins_s=time_bins,\n",
    "        spatial_bins_um=depth_bins,\n",
    "    )\n",
    "    recording_motion_corrected = InterpolateMotionRecording(\n",
    "        recording,\n",
    "        motion_object,\n",
    "        border_mode='force_extrapolate',\n",
    "    )\n",
    "\n",
    "    print(\"Step 4: Running kilosort...\")\n",
    "    params = si.get_default_sorter_params(sorter_name_or_class='kilosort4')\n",
    "    params_kilosort4 = {\n",
    "        'do_correction': False,\n",
    "        'bad_channels': None #would need to change if we choose not to delete bad channels\n",
    "    }\n",
    "    \n",
    "    sorting = si.run_sorter('kilosort4', recording_motion_corrected, remove_existing_folder=True, folder=preprocess_folder.parent / 'kilosort4_preprocess',\n",
    "                            docker_image=False, verbose=True, **params_kilosort4)\n",
    "\n",
    "    print(\" Done! Drift-corrected kilosort ran successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1161a236-d60d-4ffd-aa50-3042a4a4aafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pool_engine': 'process', 'n_jobs': 40, 'chunk_duration': '1s', 'progress_bar': True, 'mp_context': None, 'max_threads_per_worker': 1}\n",
      "Step 1: Setting up folders and reading raw recording...\n",
      "/ix1/pmayo/lab_NHPdata/kendra_scrappy_0124a_g0/kendra_scrappy_0124a_g0_imec0/preprocess\n",
      "Step 2: Estimating motion correction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca0aec39e26458f9a6e232691b7d2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "noise_level (workers: 20 processes):   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938c545b69b747fbb5a67474a0b48b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "detect peaks using locally_exclusive (workers: 40 processes):   0%|          | 0/6273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d49438faeb4a0c8ec41d0d977a6275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "localize peaks using monopolar_triangulation (workers: 40 processes):   0%|          | 0/6273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/ihome/pmayo/knoneman/.conda/envs/kilosort/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/ihome/pmayo/knoneman/.conda/envs/kilosort/lib/python3.10/concurrent/futures/process.py\", line 323, in run\n",
      "    self.terminate_broken(cause)\n",
      "  File \"/ihome/pmayo/knoneman/.conda/envs/kilosort/lib/python3.10/concurrent/futures/process.py\", line 463, in terminate_broken\n",
      "    work_item.future.set_exception(bpe)\n",
      "  File \"/ihome/pmayo/knoneman/.conda/envs/kilosort/lib/python3.10/concurrent/futures/_base.py\", line 561, in set_exception\n",
      "    raise InvalidStateError('{}: {!r}'.format(self._state, self))\n",
      "concurrent.futures._base.InvalidStateError: CANCELLED: <Future at 0x7f43d49d70a0 state=cancelled>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m IN2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m spikeglx_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ix1/pmayo/lab_NHPdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIN1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43msi_preprocess_with_medicine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspikeglx_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMEC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIN2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36msi_preprocess_with_medicine\u001b[0;34m(spikeglx_folder, IMEC)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Detect, extract, and localize peaks, such as with the following pipeline\u001b[39;00m\n\u001b[1;32m     35\u001b[0m peaks \u001b[38;5;241m=\u001b[39m detect_peaks(recording, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocally_exclusive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m peak_locations \u001b[38;5;241m=\u001b[39m \u001b[43mlocalize_peaks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeaks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonopolar_triangulation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Create directory to store MEDiCINe outputs for this recording\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#medicine_output_dir = Path('path/to/medicine/output/directory')\u001b[39;00m\n\u001b[1;32m     40\u001b[0m medicine_output_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/site-packages/spikeinterface/sortingcomponents/peak_localization.py:126\u001b[0m, in \u001b[0;36mlocalize_peaks\u001b[0;34m(recording, peaks, method, ms_before, ms_after, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m pipeline_nodes \u001b[38;5;241m=\u001b[39m get_localization_pipeline_nodes(\n\u001b[1;32m    123\u001b[0m     recording, peak_retriever, method\u001b[38;5;241m=\u001b[39mmethod, ms_before\u001b[38;5;241m=\u001b[39mms_before, ms_after\u001b[38;5;241m=\u001b[39mms_after, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m job_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalize peaks using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 126\u001b[0m peak_locations \u001b[38;5;241m=\u001b[39m \u001b[43mrun_node_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m peak_locations\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/site-packages/spikeinterface/core/node_pipeline.py:615\u001b[0m, in \u001b[0;36mrun_node_pipeline\u001b[0;34m(recording, nodes, job_kwargs, job_name, gather_mode, gather_kwargs, squeeze_output, folder, names, verbose, skip_after_n_peaks, recording_slices)\u001b[0m\n\u001b[1;32m    602\u001b[0m init_args \u001b[38;5;241m=\u001b[39m (recording, nodes, skip_after_n_peaks_per_worker)\n\u001b[1;32m    604\u001b[0m processor \u001b[38;5;241m=\u001b[39m ChunkRecordingExecutor(\n\u001b[1;32m    605\u001b[0m     recording,\n\u001b[1;32m    606\u001b[0m     _compute_peak_pipeline_chunk,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs,\n\u001b[1;32m    613\u001b[0m )\n\u001b[0;32m--> 615\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecording_slices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecording_slices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m outs \u001b[38;5;241m=\u001b[39m gather_func\u001b[38;5;241m.\u001b[39mfinalize_buffers(squeeze_output\u001b[38;5;241m=\u001b[39msqueeze_output)\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/site-packages/spikeinterface/core/job_tools.py:524\u001b[0m, in \u001b[0;36mChunkRecordingExecutor.run\u001b[0;34m(self, recording_slices)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar:\n\u001b[1;32m    520\u001b[0m     results \u001b[38;5;241m=\u001b[39m tqdm(\n\u001b[1;32m    521\u001b[0m         results, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (workers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_jobs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes)\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(recording_slices)\n\u001b[1;32m    522\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_returns:\n\u001b[1;32m    526\u001b[0m         returns\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/concurrent/futures/process.py:575\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    576\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.conda/envs/kilosort/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "IN1 = 'kendra_scrappy_0124a_g0'\n",
    "IN2 = 0\n",
    "\n",
    "spikeglx_folder = f\"/ix1/pmayo/lab_NHPdata/{IN1}/\"\n",
    "\n",
    "si_preprocess_with_medicine(spikeglx_folder, IMEC=IN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2c1c8-d63d-45e4-99a5-7901e780da54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
